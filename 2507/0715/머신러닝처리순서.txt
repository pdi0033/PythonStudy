기초통계
현재의 상황을 정리하는 것, 어떤 집단의 성격을 통계량을 통해서 알아낸다.
평균, 분산, 표준편차, 중간값, 최빈값
평균 - (모든 요소를 더한 값) / (전체 데이터 개수) 나눔

연평균 동해안 바다 온도. 작년보다 조금 높아짐. - 50년치
평균만 갖고는 힘든 경우도 있더라. - 올해가 작년보다 높은 이유? 엘니뇨나 태풍이 좀 많이 있었고 
오차 - 기대값(예상값)과 평균값의 차이를 다 더하면 0이다.
분산 - 오차의 제곱의 합. 절대값 안 쓰고 제곱을 쓴 이유는 오차가 크게 보이라고.
표준분산: 통계학자들이 표본 중에서 몇 개만 뽑아볼 거라서 자유도
(기대값 - 평균값)의 제곱의 합   : R언어
—----------------------------------
		n - 1
사이킷런은 n 개로 나눈다.
표준편차 - 분산의 제곱근, 데이터의 흩어짐의 정보, boxplot로 보면 네모가 크게 나타남
평균, 표준편차
평균은 같은 표준편차가 크다라는 의미는 데이터가 극단적이다.

예) 
1. 어떤 학생이 모의고사 평균은 60이고 표준편차가 20이다.	40~80 사이
2. 어떤 학생이 모의고사 평균은 70이고 표준편차가 5이다.	65~75 사이
공장불량률 평균이 아니라 표준편차가 적어야 한다.

중간값 - 중간에 위치한 값. 데이터 개수가 11개면 6번째 값이 중간이 된다.
데이터 개수가 10이면  5, 6   (5번째값+6번째값) / 2

표준편차가 크다. => 튀는값(이상치)가 있을 경우에 평균을 왜곡 시킬 수 있다.
이때는 대표값으로 중간값을 사용한다.

평균값이 중요한 경우

범주형 자료(카테고리타입), 값이 불연속적, 연비등급 (1,2,3,4) 여기서 중간값은 중요하지 않다.
발생빈도수(frequency), 분할표(데이터프레임: value_counts, 넘파이: unique, bins)
차를 100대를 검사
1등급		2등급		3등급		4등급
5		10		60		25

각자 타겟일 경우도 있지만, 특성일 수도 있다.


범주형-연비등급, 분할표, 히스토그램 - 구간별로 데이터 몇 개 있는지, 차이검정
비범주형(연속형)-연비자체, 평균, 표준편차, 중간값, 차이검정


차이검정
형주씨랑 준오씨라 갖고 있는 책종류를 따져봄
형주			준오		- 둘 사이에 차이가 있는지?
웹소설(100)		120		객관화시키는 방법 카이제곱 검증
추리소설(400)	380		R언어
자연주의(50)		0		차이가 있긴 한데 본질적인 차이냐?
신비주의(10)		15		유의수준 0.05 밑이어야 차이가 있다고 받아들인다.

정규분포가 있으면 키가 2미터 7인데  전체 데이터중에서 2미터 7일 확률이 0.05 미만이어야 과학적으로 이건 확실히 차이가 난다.
범주형 데이터는 - 카이제곱검증
비범주형 데이터는 - T-test 검증
그룹 2개 만들어서 한그룹은 신약을 주고 한그룹은 밀가루로 만든약을 준다.
유의수준 0.05 미만이어야 효과가 있다.

대립가설 - 현재의 가설을 폐기할 가설 (한국남자키가 173보다 작다 또는 173보다 크다)
귀무가설 - 현재의 상태(한국남자키가 173)


추론 통계
기초 통계 바탕으로 예측이 들어갈 때
머신러닝, 딥러닝
머신러닝 지도학습, 비지도학습, 강화학습이 있다.
지도학습 - 라벨이 있을 때, 타겟이 있을 때
비지도학습 - 라벨이 없을 때, 타겟이 없을 때, 보통은 지도학습 전단계로 특성공학을 담당한다.
새로운 특성을 만들거나, 차원을 축소하거나, 연관성을 찾아보거나, 스케일링 등
강화학습 - 알파고, 게임알고리즘한테 당근과 채찍을 주는 경우 3.9이하까지만 지원중
dfs(깊이우선), bfs(너비우선) - 둘다 안 쓴다.
반드시 별도의 가상환경을 만들어야 한다. 현재 3.9까지.








머신러닝 처리순서
1. 타겟이 분류냐 회귀냐
회귀의 목적은 연속된 값 한 개 맞추기. 키나 집값, 성적도 점수로 맞추면 회귀
분류는 이진분류, 다중분류, 확률 무엇인가 될 확률, 합격할 확률, 개가 될 확률
이진분류 - 둘중하나
다중분류 - 여러 개 중 하나

스마트팜
boxplot, 산포도(히트맵), 히스토그램(분류), 분할표(분류)
상관계수

2. 각 필드별 결측치 확인
    결측치를 열을 제거하거나 행을 제거할 수도 있다.
    혹은 지나치게 결측치가 많을 경우에는 대체값(평균, 중간(비범주형일 때는 평균 또는 중간값), 최빈값(데이터가 범주형일 때))

3. 이상치 제거
    boxplot 이 시각화에 좋다.		맨아래 맨위 동그라미
    IQR 방식 알고리즘을 많이 사용함, 함수는 내가 직접 만들어야 한다.

4. 중복값 제거

5. 데이터 자체가 잘못 들어온 값
    value_counts 함수나 Unique로 체크하기
    값 바꾸기를 시도하거나 행을 삭제


라벨링 -> 꽃이미지분류시 타겟팅한 거 
6. 라벨인코딩 또는 원핫인코딩
라벨인코딩 - 성별. male, female 정보가 문자열로 들어오면 연산이 불가능하니까
	male=0, female=1, 값범위가 3~4개 미만일 때

	LabelEncoder, OrdinalEncoder
	
라벨인코딩 범위가 큰 경우 - 직업 입력할 때
1. 회사원, 2. 주부, 3. 학생, 4. 공무원, 5. 기타
직업 -> 가중치를 구해야 한다.
1~5 큰 수가 중요하다고 판단하면서 가중치를 구한다.
결과가 왜곡된다.
직업_1, 직업_2, 직업_3, 직업_4, 직업_5
1	0	   0	       0		0
0	1	   0	       0		0
…

7. 스케일링
연산이니까 값의 범위가 너무 차이가 나면 큰값 기준으로 가중치가 결정된다.
y = w1x1 + w2x2 + w3x3 + … + wnxn + b
w1, w2, w3, …. , b	계수라고도 부르고 가중치라고도 부른다.
서포트벡터머신하고 딥러닝은 단위가 영향을 미치는 알고리즘이다.
스케일을 맞춘다. 정규화, 표준화

8. 학습하고 특성의 개수가 많을 경우는 특성의 중요도 확인

9. 주성분분석

10. 여러가지 모델로 학습하기, GridSearchCV 사용도 가능

11. 평가지표
회귀인 경우와 분류인 경우가 다르다.
회귀
    mae - Mean Absolute Error - 평균 절대 오차. |기대값-실제값|/개수, 이상치에 덜 민감
    mse - Mean Squared Error - 평균 제곱 오차. (기대값-실제값)의 제곱/개수, 이상치에 민감
        딥러닝에서 손실함수(오차계산시 많이 쓰임)
    rmse - Root Mean Squared Error - mse의 제곱근.
    R2 - 결정계수. 현재 회귀 계열에서 score함수의 결과값이 결정계수이다.
        1- 예측 뛰어남, 0으로 갈수록 별로, -로 가면 심각한 경우이다.
    # 취약점 - 독립변수(특성)의 수가 증가하면 예측력이 높지 않은데 이값이 좋아지는 경우가 있다.
    업그레이드 버전 > Adjusted R-squared : R언어가 이걸 쓴다.
    mape - Mean Absolute Percentage Error - 퍼센트로 따진거

분류
    문제점: 데이터의 불균형성 때문에 제대로 예측이 안 되는 경우가 있다.
    암환자 같은 경우에 예측의 정확성만 가지고 좋은 모델이라고 평가할 수 있다.
    반대의 경우 iris 데이터의 경우 균등데이터셋(라벨기준으로)
    iris 가 종을 못맞춰도 그러려니 한다.

    암환자 음성 -> 양성: 괜찮다. 양성 ->음성 : 검진을 받을 타임을 놓친 사람들
    데이터가 불균등이 너무 심해서 아무거나 한가지로 대답을 함. 그 경우에도 정확도만 가지고는 파악을 못한다.

    정확도 : 맞춘개수/전체개수	양성 - 3%, 음성 - 97%
    이때 전부 음성이라고 해도 97%의 정확도를 보인다.
    그래서 별도의 평가지표를 가져야 한다.

오차행렬(Confusion  Matrix) – 대각선이 정상임
		예측양성	예측음성
실제양성	TP		FN
실제음성	FP		TN

TP - True Positive: 실제 양성
FP - False Positive: 가짜 양성, 음성인데 양성으로 맞춘
TN - True Negative: 실제 음성
FN - False Negative: 가짜 음성, 양성인데 음성으로 맞춘

암환자셋 양성을 0이라고 했고 음성을 1로 봄
-> Confusion Matrix 에 맞게 만들려면
양성을 1로 음성을 0으로 바꿔서 분석하기

1) 정확도 - 올바르게 예측한 비율, 불균형 데이터셋일 때, 위험한 상태 예측같은 경우 정확도가 도움이 안 된다.
분류모델들의 score함수는 정확도를 말한다.
아주 운 나쁜 경우에 한 가지만 대답해도 정확도는 높을 수 있다.

2) 정밀도(precision) - 모델이 양성으로 예측했는데 실제 양성인 비율
스팸이 아닌데 스팸으로 예측하고 스팸함으로 보내는 경우가 문제가 될 수 있다.

3) 재현율(recall) - 민감도. 실제 양성인 것 중에서 모델이 양성으로 예측한 비율
FN을 줄이고자 할 때 중요. 암환자

4) f1-score - 정밀도와 재현율의 조화평균