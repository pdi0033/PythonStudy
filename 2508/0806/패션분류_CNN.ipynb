{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ppA9cXCUq16Y"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pickle\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#저장 파일명 지정하기\n",
        "model_path = \"fashion_mnist_model.keras\" #확장자를 keras로 하거나 없거나\n",
        "history_path = \"fashion_mnist_history.bin\" #이 파일 확장자는 마음대로"
      ],
      "metadata": {
        "id": "9BSip58YrDbW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data():\n",
        "  #이 데이터는 케라스가 제공한다 -> 유명함\n",
        "  (X_train, y_train), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "  print(X_train.shape)\n",
        "  print(y_train.shape)\n",
        "\n",
        "  print(X_test.shape)\n",
        "  print(y_test.shape)\n",
        "\n",
        "  #60000, 28, 28   흑백이미지  28 by 28  훈련셋이 60000, 테스트셋이 10000\n",
        "  print(y_test[:10])\n",
        "  return X_train, y_train, X_test, y_test"
      ],
      "metadata": {
        "id": "uw5Nd8WKrmYU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#1. 결측치나 이상치가 없다. 이유는 이미지파일 불러서 numpy로 바꾼거라\n",
        "#2. 표준화나 정규화\n",
        "#3. target 의 라벨인코딩 또는 원핫인코딩  하기싫으면  loss에 sparse_categorical_crossentropy를 사용하면 된다\n",
        "def preprocessing(X_train, y_train, X_test, y_test):\n",
        "  X_train = X_train.astype(\"float32\")/255\n",
        "  X_test = X_test.astype(\"float32\")/255\n",
        "  X_train = np.expand_dims(X_train, -1) #차원버전\n",
        "  X_test = np.expand_dims(X_test, -1) #차원추가\n",
        "  print(X_train.shape)\n",
        "  print(X_test.shape)\n",
        "  return X_train,  y_train, X_test, y_test\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "oUKKF5AcyEoD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getModel():\n",
        "  data_argumentation = keras.Sequential(\n",
        "      [\n",
        "          layers.RandomFlip(\"horizontal\"),\n",
        "          layers.RandomRotation(0.1),\n",
        "          layers.RandomZoom(0.2)\n",
        "      ]\n",
        "  )\n",
        "\n",
        "  model = keras.Sequential( [\n",
        "      #data_argumentation,,\n",
        "      layers.Conv2D(32, kernel_size=(3,3), activation=\"relu\", input_shape=((28,28,1))),\n",
        "      layers.MaxPooling2D(pool_size=(2,2)),\n",
        "      layers.Conv2D(64, kernel_size=(3,3), activation=\"relu\"),\n",
        "      layers.MaxPooling2D(pool_size=(2,2)),\n",
        "      layers.Flatten(),  #CNN와 완전연결망을 연결시킨다\n",
        "      layers.Dense(64, activation='relu'),\n",
        "      layers.Dense(32, activation='relu'),\n",
        "      layers.Dense(10, activation='softmax')\n",
        "  ])\n",
        "\n",
        "  model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "  model.summary()\n",
        "  return model\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "F2YI3DDaz4h6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def study(model, X_train, y_train, X_test, y_test):\n",
        "\n",
        "  early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
        "  history = model.fit(X_train, y_train, epochs=100, validation_split=0.2, callbacks=[early_stopping])\n",
        "\n",
        "  model.save(model_path)\n",
        "  with open(history_path, 'wb') as f:\n",
        "    pickle.dump(history.history, f)\n",
        "\n",
        "  return history\n"
      ],
      "metadata": {
        "id": "Se4MO6wG2WG2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train, X_test, y_test = load_data()\n",
        "X_train, y_train, X_test, y_test = preprocessing(X_train,  y_train, X_test, y_test)\n",
        "model = getModel()\n",
        "study(model, X_train, y_train, X_test, y_test)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DAZ2C1sAsSm2",
        "outputId": "5ec42c0e-4afb-47be-a437-795afe2dd610"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n",
            "(60000,)\n",
            "(10000, 28, 28)\n",
            "(10000,)\n",
            "[9 2 1 1 6 1 4 6 5 7]\n",
            "(60000, 28, 28, 1)\n",
            "(10000, 28, 28, 1)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_27\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_27\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_26 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_26 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_27 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_27 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_13 (\u001b[38;5;33mFlatten\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_39 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │       \u001b[38;5;34m102,464\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_40 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_41 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m330\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">102,464</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">330</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m123,690\u001b[0m (483.16 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">123,690</span> (483.16 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m123,690\u001b[0m (483.16 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">123,690</span> (483.16 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 27ms/step - accuracy: 0.7499 - loss: 0.7017 - val_accuracy: 0.8744 - val_loss: 0.3579\n",
            "Epoch 2/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 28ms/step - accuracy: 0.8742 - loss: 0.3461 - val_accuracy: 0.8880 - val_loss: 0.3090\n",
            "Epoch 3/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 29ms/step - accuracy: 0.8950 - loss: 0.2889 - val_accuracy: 0.8885 - val_loss: 0.3096\n",
            "Epoch 4/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 28ms/step - accuracy: 0.9068 - loss: 0.2549 - val_accuracy: 0.9051 - val_loss: 0.2649\n",
            "Epoch 5/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 29ms/step - accuracy: 0.9201 - loss: 0.2210 - val_accuracy: 0.8988 - val_loss: 0.2776\n",
            "Epoch 6/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 27ms/step - accuracy: 0.9254 - loss: 0.2024 - val_accuracy: 0.9009 - val_loss: 0.2814\n",
            "Epoch 7/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 28ms/step - accuracy: 0.9319 - loss: 0.1836 - val_accuracy: 0.9107 - val_loss: 0.2571\n",
            "Epoch 8/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 27ms/step - accuracy: 0.9383 - loss: 0.1653 - val_accuracy: 0.9057 - val_loss: 0.2794\n",
            "Epoch 9/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 28ms/step - accuracy: 0.9456 - loss: 0.1472 - val_accuracy: 0.9141 - val_loss: 0.2561\n",
            "Epoch 10/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 29ms/step - accuracy: 0.9486 - loss: 0.1364 - val_accuracy: 0.9128 - val_loss: 0.2631\n",
            "Epoch 11/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 28ms/step - accuracy: 0.9563 - loss: 0.1196 - val_accuracy: 0.9034 - val_loss: 0.2986\n",
            "Epoch 12/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 29ms/step - accuracy: 0.9586 - loss: 0.1107 - val_accuracy: 0.9123 - val_loss: 0.2827\n",
            "Epoch 13/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 28ms/step - accuracy: 0.9616 - loss: 0.1023 - val_accuracy: 0.9088 - val_loss: 0.3197\n",
            "Epoch 14/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 27ms/step - accuracy: 0.9654 - loss: 0.0900 - val_accuracy: 0.9070 - val_loss: 0.3231\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7bdf5328c0d0>"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "#평가하기\n",
        "def evalute_model(X_test, y_test):\n",
        "  model = keras.models.load_model(model_path)\n",
        "  with open(history_path, 'rb') as f:\n",
        "    history = pickle.load(f)\n",
        "  #모델하고 히스토리 불러오기\n",
        "\n",
        "  #예측하기\n",
        "  y_pred = model.predict(X_test) #예측확률\n",
        "  print(y_pred.shape)  #softmax함수가 하는일이 실제 출력값들은 가중치\n",
        "  #가중치들을 확률로 바꿔서 전달하는 함수가 softmax\n",
        "  print(y_pred[:10])\n",
        "  y_pred = np.argmax(y_pred, axis=1) #최대값 위치를 찾아온다 벡터연산\n",
        "  print(y_pred[:10])\n",
        "  print(y_test[:10])\n",
        "\n",
        "  #모델 평가\n",
        "  loss, accuracy = model.evaluate(X_test, y_test)\n",
        "  print(f\"테스트셋 손실 {loss}\")\n",
        "  print(f\"테스트셋 정확도 {accuracy}\")\n",
        "\n",
        "  #머신러닝에서 썼던 평가방법을 여기도 쓸 수 있다 - 혼동행렬\n",
        "  print(\"혼동행렬\")\n",
        "  print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "  print(\"\\n\\n\\n분류보고서\")\n",
        "  class_names = ['T-shirt', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt',\n",
        "                 'Sneaker', 'Bag', 'Ankle boot']\n",
        "\n",
        "  print(classification_report(y_test, y_pred, target_names=class_names))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "evalute_model(X_test, y_test)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GEt1BNDqD0LG",
        "outputId": "6a2ba85c-3376-414f-c6bc-a1e6706cbda5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step\n",
            "(10000, 10)\n",
            "[[9.96526126e-11 2.18388103e-11 1.43640823e-13 2.52989771e-08\n",
            "  2.18241633e-10 3.56191210e-09 1.17473287e-09 7.22525192e-06\n",
            "  2.74910194e-12 9.99992669e-01]\n",
            " [7.89188270e-10 1.32248509e-11 9.99123096e-01 1.91376148e-06\n",
            "  2.50493059e-07 1.38791329e-14 8.74724530e-04 7.66645370e-22\n",
            "  1.87991911e-09 9.02932988e-14]\n",
            " [1.00685053e-17 9.99999940e-01 2.45215128e-21 2.24464054e-20\n",
            "  6.81161398e-29 2.95376458e-22 3.46656854e-20 6.47918380e-31\n",
            "  1.56192726e-27 1.87288393e-30]\n",
            " [4.12441921e-19 9.99999940e-01 6.48837112e-20 2.07661147e-19\n",
            "  5.26988359e-26 5.84701700e-27 2.38827852e-19 1.80669919e-33\n",
            "  1.04440360e-29 3.82887380e-31]\n",
            " [5.08368015e-01 3.38573995e-11 1.04255640e-04 2.29169743e-07\n",
            "  2.39833817e-03 9.67311578e-11 4.89129186e-01 1.10370285e-12\n",
            "  1.16786199e-11 2.93070207e-10]\n",
            " [4.74599820e-20 9.99999940e-01 7.72738493e-20 1.32935460e-17\n",
            "  1.80937303e-28 3.84001869e-24 6.37791731e-20 7.65226389e-34\n",
            "  9.71132269e-30 1.52708142e-31]\n",
            " [6.93260588e-11 4.55357323e-13 2.02914489e-05 2.29126673e-09\n",
            "  9.99908626e-01 8.33802886e-15 7.10277091e-05 2.14258681e-20\n",
            "  1.53756470e-13 4.68513670e-16]\n",
            " [9.82096171e-05 3.78896159e-09 2.37534023e-05 1.31496654e-05\n",
            "  1.93636462e-01 3.93898525e-10 8.06217134e-01 2.36134740e-11\n",
            "  1.11314785e-05 1.25836749e-07]\n",
            " [1.06967256e-07 6.20109975e-14 9.98619409e-10 7.05615991e-12\n",
            "  3.66604178e-11 9.99996245e-01 6.08789711e-12 3.54570625e-06\n",
            "  1.97986569e-08 5.14453202e-10]\n",
            " [2.65459654e-09 4.62567094e-12 3.64033165e-10 4.93174674e-08\n",
            "  1.21521432e-13 4.31492758e-10 1.46907511e-13 9.99999940e-01\n",
            "  1.47668128e-11 1.78722015e-08]]\n",
            "[9 2 1 1 0 1 4 6 5 7]\n",
            "[9 2 1 1 6 1 4 6 5 7]\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8975 - loss: 0.3420\n",
            "테스트셋 손실 0.3479461371898651\n",
            "테스트셋 정확도 0.9000999927520752\n",
            "혼동행렬\n",
            "[[802   1  20  23   2   2 141   1   8   0]\n",
            " [  2 980   1  13   1   0   2   0   1   0]\n",
            " [ 19   1 833   9  76   0  61   0   1   0]\n",
            " [ 16   2   9 926  22   0  21   1   3   0]\n",
            " [  0   2  25  27 892   0  49   0   5   0]\n",
            " [  1   0   0   1   0 962   0  27   0   9]\n",
            " [ 99   1  58  35  98   0 695   0  14   0]\n",
            " [  0   0   0   0   0  10   0 979   1  10]\n",
            " [  1   1   3   4   3   1   1   1 984   1]\n",
            " [  0   0   0   0   0   4   1  46   1 948]]\n",
            "\n",
            "\n",
            "\n",
            "분류보고서\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     T-shirt       0.85      0.80      0.83      1000\n",
            "     Trouser       0.99      0.98      0.99      1000\n",
            "    Pullover       0.88      0.83      0.85      1000\n",
            "       Dress       0.89      0.93      0.91      1000\n",
            "        Coat       0.82      0.89      0.85      1000\n",
            "      Sandal       0.98      0.96      0.97      1000\n",
            "       Shirt       0.72      0.69      0.71      1000\n",
            "     Sneaker       0.93      0.98      0.95      1000\n",
            "         Bag       0.97      0.98      0.98      1000\n",
            "  Ankle boot       0.98      0.95      0.96      1000\n",
            "\n",
            "    accuracy                           0.90     10000\n",
            "   macro avg       0.90      0.90      0.90     10000\n",
            "weighted avg       0.90      0.90      0.90     10000\n",
            "\n"
          ]
        }
      ]
    }
  ]
}